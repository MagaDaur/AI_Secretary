{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eresque/anaconda3/envs/urfo_hack_2024/lib/python3.12/site-packages/pyannote/audio/core/io.py:43: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.\n",
      "  torchaudio.set_audio_backend(\"soundfile\")\n",
      "/home/eresque/anaconda3/envs/urfo_hack_2024/lib/python3.12/site-packages/torch_audiomentations/utils/io.py:27: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.\n",
      "  torchaudio.set_audio_backend(\"soundfile\")\n"
     ]
    }
   ],
   "source": [
    "# Токен для Hugging Face\n",
    "import whisperx\n",
    "import torch\n",
    "from whisperx.diarize import DiarizationPipeline\n",
    "HF_TOKEN = \"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\"\n",
    "\n",
    "\n",
    "\n",
    "def transcribe_audio(audio_file, model_name=\"large-v3\", compute_type=\"float16\"):\n",
    "    \"\"\"Транскрибация аудиофайла\"\"\"\n",
    "    # Pass the device as a string (\"cuda\" or \"cpu\")\n",
    "    model = whisperx.load_model(model_name, device=\"cuda\" if torch.cuda.is_available() else \"cpu\", compute_type=compute_type)\n",
    "    transcription_result = model.transcribe(audio_file)\n",
    "    return transcription_result\n",
    "\n",
    "def perform_diarization(audio_file):\n",
    "    \"\"\"Диаризация аудиофайла и выделение самого длинного сегмента используя WhisperX\"\"\"\n",
    "    # Использование WhisperX DiarizationPipeline\n",
    "    diarization_pipeline = DiarizationPipeline(use_auth_token=HF_TOKEN, device='cuda')\n",
    "    diarized = diarization_pipeline(audio_file)\n",
    "\n",
    "    # return the diarization result\n",
    "    return diarized\n",
    "\n",
    "def count_unique_speakers(diarize_df):\n",
    "    \"\"\"Подсчёт уникальных спикеров в результатах диаризации\"\"\"\n",
    "    unique_speakers = diarize_df['speaker'].nunique()\n",
    "    return unique_speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13a769017175487aabab6f89c26a26cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/2.39k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dd1bd39ef054298920e9c683cabca74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/340 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae767f33154044fbb6d75bd126d25ae5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.48M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbf8a792b3fa4b5e8d10d5dc23ae83fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocabulary.json:   0%|          | 0.00/1.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "876fcc067af64970a1a185d1274a6444",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.bin:   0%|          | 0.00/3.09G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.2.4. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../../.cache/torch/whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No language specified, language will be first be detected for each audio file (increases inference time).\n",
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.3.0+cu121. Bad things might happen unless you revert torch to 1.x.\n",
      "Detected language: ru (0.98) in first 30s of audio...\n",
      "Transcription time: 281.39105129241943\n",
      "Diarization time: 2.883897304534912\n",
      "Transcribed text:  Вы знаете, что в Государственную Думу у меня вынесено предложение о назначении вас на должность председателя правительства Российской Федерации. Совсем недавно мы встречались с коллегами и оценивали работу правительства за предыдущие годы. Сделано в сложных условиях немало, и мне кажется, что было бы правильно, если бы  Мы продолжили с вами работу, и вы продолжили работу в качестве председателя правительства.  Мы с вами говорили и о структуре, говорили о персонале. В целом, думаю, мы на правильном пути. И очень надеюсь на то, что депутаты Государственной Думы, а вы не так давно были в Госдуме, отчитывались, они знают, что и как правительство, и вами, как председателям правительства, сделано за последние годы, оценят должным образом и поддержат вас в ходе ваших консультаций, предстоящих сегодня в  На фракциях, а затем и на заседании парламента. После того, как это произойдёт, а надеюсь, что это так и будет, мы с вами встретимся ещё раз и поговорим более подробно тогда о ваших предложениях. В соответствии с Конституцией будем действовать. Надеюсь, что вам удастся убедить депутатов в Государственной Думе по поводу кандидатуры ваших заместителей и федеральных министров.  Спасибо, уважаемый Владимир Владимирович. Хочу в первую очередь поблагодарить вас за доверие, которое вы оказали мне, за задачи, которые вы поставили перед Федеральным собранием в своем послании и, конечно, те национальные цели развития, которые были указаны в новом майском указе.  Это ориентир и приоритеты в работе правительства. Хочу вас заверить, что никаких пауз в работе правительства не будет. Мы будем продолжать текущую работу. Также считаю, что мы должны обеспечить преемственность по всем национальным целям, которые были до этого, в 204 и 474 указе. Сделаем все для развития нашей экономики, чтобы оправдать доверие наших людей. И уверен, что под вашим руководством мы все задачи, которые поставлены, решим.  Мы с вами вместе и с коллегами из правительства формулировали национальные цели развития. Это, конечно, главное, к чему мы должны стремиться, к реализации этих целей по всем направлениям. И, как показывает практика последних лет, в целом у нас…  И получается добиваться тех результатов, которые нужны стране. А в сегодняшних непростых условиях, конечно, нужно собраться и нужно организовать работу именно так, как мы с вами договорились на последней встрече с правительством, работать без пауз.\n",
      "Number of speakers: 2\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def base(audio_file):\n",
    "    # Measure transcription time\n",
    "    start_time1 = time.time()\n",
    "    transcription_result = transcribe_audio(audio_file)\n",
    "    end_time1 = time.time()\n",
    "    processing_time = end_time1 - start_time1\n",
    "    print(f'Transcription time: {processing_time}')\n",
    "\n",
    "    \n",
    "\n",
    "    # Measure diarization time\n",
    "    start_time = time.time()\n",
    "    diarize_df = perform_diarization(audio_file)\n",
    "    end_time = time.time()\n",
    "    processing_time1 = end_time - start_time\n",
    "    print(f'Diarization time: {processing_time1}')\n",
    "\n",
    "    # Count unique speakers\n",
    "    num_speakers = count_unique_speakers(diarize_df)\n",
    "\n",
    "    # Extract text from transcription result\n",
    "    if isinstance(transcription_result, list):\n",
    "        text = \" \".join([item['text'] for item in transcription_result])\n",
    "    elif isinstance(transcription_result, dict) and 'segments' in transcription_result:\n",
    "        text = \" \".join([segment['text'] for segment in transcription_result['segments']])\n",
    "    else:\n",
    "        text = transcription_result.get('text', '')\n",
    "\n",
    "    return text, num_speakers\n",
    "\n",
    "# Example usage\n",
    "text, num_speakers = base('аудио/Встреча 8. .m4a')\n",
    "print(f'Transcribed text: {text}')\n",
    "print(f'Number of speakers: {num_speakers}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.2.4. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../../.cache/torch/whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No language specified, language will be first be detected for each audio file (increases inference time).\n",
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.3.0+cu121. Bad things might happen unless you revert torch to 1.x.\n",
      "Detected language: ru (1.00) in first 30s of audio...\n",
      "Transcription time: 32.58378529548645\n",
      "Diarization time: 10.450380086898804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.2.4. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../../.cache/torch/whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No language specified, language will be first be detected for each audio file (increases inference time).\n",
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.3.0+cu121. Bad things might happen unless you revert torch to 1.x.\n",
      "Detected language: ru (1.00) in first 30s of audio...\n",
      "Transcription time: 25.41658878326416\n",
      "Diarization time: 7.72376012802124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.2.4. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../../.cache/torch/whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No language specified, language will be first be detected for each audio file (increases inference time).\n",
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.3.0+cu121. Bad things might happen unless you revert torch to 1.x.\n",
      "Detected language: ru (0.99) in first 30s of audio...\n",
      "Transcription time: 33.45371389389038\n",
      "Diarization time: 10.222927570343018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.2.4. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../../.cache/torch/whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No language specified, language will be first be detected for each audio file (increases inference time).\n",
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.3.0+cu121. Bad things might happen unless you revert torch to 1.x.\n",
      "Detected language: ru (1.00) in first 30s of audio...\n",
      "Transcription time: 13.42027997970581\n",
      "Diarization time: 4.556212425231934\n",
      "Dataset has been created and saved to 'dataset.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def create_dataset_from_audio_folder(folder_path):\n",
    "    # Список для хранения данных\n",
    "    data = []\n",
    "\n",
    "    # Перебор всех файлов в папке\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith(\".wav\") or file_name.endswith(\".mp3\") or file_name.endswith(\".m4a\") or file_name.endswith(\".ogg\"):  # Учитываем только аудиофайлы\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            \n",
    "            # Получаем транскрибированный текст и число спикеров\n",
    "            try:\n",
    "                transcribed_text, number_of_speakers = base(file_path)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {file_name}: {e}\")\n",
    "                transcribed_text, number_of_speakers = \"Ошибка при обработке\", 0\n",
    "            \n",
    "            # Добавляем данные в список\n",
    "            data.append({\n",
    "                'Наименование аудиозаписи': file_name,\n",
    "                'Транскрибированный текст': transcribed_text,\n",
    "                'Число спикеров': number_of_speakers\n",
    "            })\n",
    "\n",
    "    # Создаем DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Сохраняем DataFrame в CSV файл\n",
    "    df.to_csv('dataset.csv', index=False, encoding='utf-8-sig')\n",
    "    print(\"Dataset has been created and saved to 'dataset.csv'\")\n",
    "\n",
    "# Пример использования\n",
    "folder_path = 'audio_test/'\n",
    "create_dataset_from_audio_folder(folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 287 fields in line 4, saw 356\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dataset \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubmission.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m dataset\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubmission.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/urfo_hack_2024/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/anaconda3/envs/urfo_hack_2024/lib/python3.12/site-packages/pandas/io/parsers/readers.py:626\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[0;32m--> 626\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\u001b[38;5;241m.\u001b[39mread(nrows)\n",
      "File \u001b[0;32m~/anaconda3/envs/urfo_hack_2024/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1923\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1916\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[1;32m   1917\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1918\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1919\u001b[0m     (\n\u001b[1;32m   1920\u001b[0m         index,\n\u001b[1;32m   1921\u001b[0m         columns,\n\u001b[1;32m   1922\u001b[0m         col_dict,\n\u001b[0;32m-> 1923\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mread(  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m         nrows\n\u001b[1;32m   1925\u001b[0m     )\n\u001b[1;32m   1926\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1927\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/anaconda3/envs/urfo_hack_2024/lib/python3.12/site-packages/pandas/io/parsers/c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[0;32m--> 234\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39mread_low_memory(nrows)\n\u001b[1;32m    235\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[0;32mparsers.pyx:838\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:905\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:874\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:891\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:2061\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 287 fields in line 4, saw 356\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"submission.csv\")\n",
    "dataset.to_csv(\"submission.csv\", index=False, sep=\";\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "urfo_2024",
   "language": "python",
   "name": "urfo_2024"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
